{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment following lines if following packages are not installed in your system\n",
    "# !pip install termcolor\n",
    "# !pip install -U gensim\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "# nltk.download()\n",
    "import sys\n",
    "from nltk.corpus import stopwords\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######Global Variables######\n",
    "type1_colr = 'red' #color code for word starting with ! \n",
    "type2_colr = 'blue' #color code for word starting with *\n",
    "sim_threshold = 0.3 # threshold value of similarity between train and test categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_embeddings = KeyedVectors.load_word2vec_format(\"GoogleNews-125k.bin.gz\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sim_words(s):\n",
    "    '''\n",
    "    Finds words starting from '!' and '*' in train data\n",
    "\n",
    "    Arguments:\n",
    "    s -- training sentence(s) with some words prefixed with '!' and '*' \n",
    "\n",
    "    Returns:\n",
    "    type1 -- list of words starting from '!'\n",
    "    type2 -- list of words starting from '*'\n",
    "\n",
    "    '''\n",
    "    all_special = re.findall(r'[!*]\\w+',s)\n",
    "    type1=[]\n",
    "    type2=[]\n",
    "    for idx,w in enumerate(all_special):\n",
    "        if w.startswith('!'):\n",
    "            type1.append(all_special[idx][1:])\n",
    "        else:\n",
    "            type2.append(all_special[idx][1:])\n",
    "    return type1,type2\n",
    "\n",
    "\n",
    "# def find_similarity_train(t,wv_embeddings,simlar_threshold=0.3):\n",
    "#     '''\n",
    "#     Finds similarity between words found in function find_sim_words \n",
    "\n",
    "#     Arguments:\n",
    "#     t -- List of words starting either from ! or *  \n",
    "#     wv_embeddings -- word embeddings used for this task\n",
    "#     simlar_threshold -- Minimum required similarity threshold between words to belong to same/similar category \n",
    "    \n",
    "#     Returns:\n",
    "#     similarity - list of words if their embedding similarity is less than simlar_threshold\n",
    "\n",
    "#     '''\n",
    "#     similarity = []\n",
    "#     for i in range(len(t)-1):\n",
    "#         sim = wv_embeddings.similarity(t[i],t[i+1])\n",
    "#         if sim < simlar_threshold:\n",
    "#             similarity.append([t[i],t[i+1]])\n",
    "#     return similarity\n",
    "\n",
    "# def similarity_error(s1,s2):\n",
    "#     if len(sim1)>0:\n",
    "#         raise Exception(\"{} following elements starting with '!' desn't belong to same category\".format(sim1))\n",
    "#     if len(sim2)>0:\n",
    "#         raise Exception(\"{} following elements starting with '*' desn't belong to same category\".format(sim2))\n",
    "        \n",
    "def test_train_similarity(t1,t2,s,wv_embeddings,threshold=0.3):\n",
    "    '''\n",
    "    \n",
    "    Finds similarity between train special words(starting from ! or *) and selected test words\n",
    "    \n",
    "    Arguments:\n",
    "    t1 -- list of words from training data starting from !\n",
    "    t2 -- list of words from training data starting from *\n",
    "    s -- list of words from test data after removing punctuation and stop words \n",
    "    wv_embeddings -- pre trained embeddings of words used for this task\n",
    "    threshold -- minimum threshold for words to belong to same category\n",
    "    \n",
    "    Returns:\n",
    "    type1_test -- words from test data that belong to same/similar category as the words starting from ! in train data\n",
    "    type2_test -- words from test data that belong to same/similar category as the words starting from * in train data    \n",
    "    \n",
    "    '''\n",
    "    type1_test = []\n",
    "    type2_test = []\n",
    "    for i in s:\n",
    "        t1_sim = 0\n",
    "        t2_sim = 0\n",
    "        for x in t1:\n",
    "#             print(x,i)\n",
    "#             print(wv_embeddings.similarity(x,i),wv_embeddings.similarity(x,first_letter(i,wv_embeddings)))\n",
    "            if (wv_embeddings.similarity(x,i)>threshold) or (wv_embeddings.similarity(x,first_letter(i,wv_embeddings))>threshold):\n",
    "                t1_sim+=1\n",
    "        if len(t1)==t1_sim>0:\n",
    "            type1_test.append(i)\n",
    "        for x in t2:\n",
    "#             print(x,i)\n",
    "#             print(wv_embeddings.similarity(x,i),wv_embeddings.similarity(x,first_letter(i,wv_embeddings)))\n",
    "            if (wv_embeddings.similarity(x,i)>threshold) or (wv_embeddings.similarity(x,first_letter(i,wv_embeddings))>threshold):\n",
    "                t2_sim+=1\n",
    "        if len(t2)==t2_sim>0:\n",
    "            type2_test.append(i)           \n",
    "    return type1_test,type2_test\n",
    "\n",
    "\n",
    "def remove_punctutaion(s):\n",
    "    '''\n",
    "    Removes punctuation and stop words from the test data\n",
    "\n",
    "    Arguments:\n",
    "    s -- test sentence(s)\n",
    "    \n",
    "    Returns:\n",
    "    words -- list of words in test sentence without punctuations and stop words\n",
    "\n",
    "    '''\n",
    "    for c in string.punctuation:\n",
    "        s=s.replace(c,\"\")\n",
    "    stop = stopwords.words('english')\n",
    "    words = [i for i in s.split(' ') if i not in stop]\n",
    "    return words\n",
    "\n",
    "\n",
    "def add_color(s,words,color):\n",
    "    '''\n",
    "    Add color to specified words \n",
    "\n",
    "    Arguments:\n",
    "    s -- sentence containing selected words\n",
    "    words -- words whose colour needs to be changed\n",
    "    color -- colour to be used for changing\n",
    "    \n",
    "    Returns:\n",
    "    s -- sentence with updated colour for the selected words\n",
    "    '''\n",
    "    for w in words:\n",
    "        s = s.replace(w,colored(w,color))\n",
    "    return s\n",
    "\n",
    "\n",
    "def check_words(words):\n",
    "    '''\n",
    "    Check whether selected words exist in the vocabulary. If a word, doesn't exist in the vocabulary, then\n",
    "    program prints a message and exit.\n",
    "\n",
    "    Arguments:\n",
    "    words -- list of words to be checked\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    '''\n",
    "    for w in words:\n",
    "        try:\n",
    "            wv_embeddings.most_similar(w)\n",
    "        except KeyError as e:\n",
    "            print(\"Word --> '%s' <-- not found in vocabulary. if you have entered wrong word, kindly update it. \"% w)\n",
    "            sys.exit()\n",
    "    return words\n",
    "\n",
    "def prepare_train(train_input,find_sim_words,add_color):\n",
    "    '''\n",
    "    Prepare train data by identifying words starting from ! and *, and adding color to these words\n",
    "\n",
    "    Arguments:\n",
    "    train_input -- training sentence(s) with some words prefixed with '!' and '*' \n",
    "    find_sim_words -- function 'find_sim_words'\n",
    "    add_color -- function 'add_color'\n",
    "    \n",
    "    Returns:\n",
    "    type1 -- list of words starting from '!'\n",
    "    type2 -- list of words starting from '*'\n",
    "    train_input -- updated train input, ready to be displayed\n",
    "\n",
    "    '''\n",
    "    type1,type2 = find_sim_words(train_input)\n",
    "    check_words(type1+type2) #check if all the words exist in vaocabulary. \n",
    "                                                  # If not mention the word not found in vocab and exit.\n",
    "    train_input = add_color(train_input,type1,type1_colr)\n",
    "    train_input = add_color(train_input,type2,type2_colr)\n",
    "    train_input = train_input.replace('*|!','')\n",
    "    train_input = re.sub('[*!]','',train_input)\n",
    "    return type1, type2, train_input\n",
    "\n",
    "def first_letter(w,wv_embeddings):\n",
    "    '''\n",
    "    Sometimes discripancies between cases of first letter can impact the similarity between words. For example, \n",
    "    lion and tiger has similarity around 0.5, however, similarity between Lion and tiger is less than 0.2. This \n",
    "    function changes the case of first letter.\n",
    "\n",
    "    Arguments:\n",
    "    w -- word, for which case of 1st letter to be updated\n",
    "    \n",
    "    Returns:\n",
    "    w_new -- update word if word exists in the vocab, else the original word\n",
    "    '''\n",
    "    if w[0].islower():\n",
    "        w_new = w[0].upper() + w[1:]\n",
    "    else: w_new = w[0].lower() + w[1:]\n",
    "    if w_new not in wv_embeddings.vocab:\n",
    "#         return w_new\n",
    "#     w_new = w\n",
    "#     else: return w\n",
    "        w_new = w\n",
    "    return w_new\n",
    "    \n",
    "def get_test_output(test_input,type1,type2,remove_punctutaion,check_words,test_train_similarity,add_color):\n",
    "    '''\n",
    "    Generates the output\n",
    "\n",
    "    Arguments:\n",
    "    test_input -- test input for which categories of word similar to train data, need to be identified\n",
    "    type1 -- words from train data starting from !\n",
    "    type2 -- words from train data starting from *\n",
    "    remove_punctutaion -- function 'remove_punctutaion'\n",
    "    check_words -- function 'check_words'\n",
    "    test_train_similarity -- function 'test_train_similarity'\n",
    "    add_color -- function 'add_color'\n",
    "    \n",
    "    Returns:\n",
    "    op - output data to be displayed\n",
    "    '''\n",
    "\n",
    "    test = remove_punctutaion(test_input)\n",
    "    check_words(test)\n",
    "#     print(test)\n",
    "    test1_words,test2_words = test_train_similarity(type1,type2,test,wv_embeddings,threshold = 0.3)\n",
    "#     print(test1_words,test2_words)\n",
    "    op = add_color(test_input,test1_words,type1_colr)\n",
    "    op = add_color(op,test2_words,type2_colr)\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter Train data in following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = \"I saw a *Lion in the zoo yesterday. Today my *dog is missing. I'm going to !India but I may end up in !Germany.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input after processing --> I saw a \u001b[34mLion\u001b[0m in the zoo yesterday. Today my \u001b[34mdog\u001b[0m is missing. I'm going to \u001b[31mIndia\u001b[0m but I may end up in \u001b[31mGermany\u001b[0m.\n"
     ]
    }
   ],
   "source": [
    "type1,type2,train_input = prepare_train(train_input,find_sim_words,add_color)\n",
    "print('Train input after processing -->',train_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter Test data in following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = \"My parrot is crazy. I should have bought a cat instead when i visited Australia.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My \u001b[34mparrot\u001b[0m is crazy. I should have bought a \u001b[34mcat\u001b[0m instead when i visited \u001b[31mAustralia\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "test_op = get_test_output(test_input,type1,type2,remove_punctutaion,check_words,test_train_similarity,add_color)\n",
    "print(test_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
